{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "82a01b94-b646-447d-9b8f-47e2f8a1aebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ETL Pipeline started...\n",
      "Data extraction completed\n",
      "Started Data Cleaning and Transformation for customer data\n",
      "Data Cleaning and Tranformation completed, Loaded the clean data to customers_cleaned.csv\n",
      "Started Data Cleaning and Transformation for products data\n",
      "Data Cleaning and Transformation completed, Loaded the clean data to products_cleaned.csv\n",
      "Started Data Cleaning and Transformation for sales data\n",
      "Data Cleaning and Transformation completed, Loaded the clean data to orders_cleaned.csv and order_items_cleaned.csv\n",
      "Data cleaning and transformation completed\n",
      "-----------------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------------\n",
      "Connected to MySQL database 'fleximart'\n",
      "Customers loaded successfully: 25\n",
      "Products loaded successfully: 20\n",
      "Orders loaded successfully: 35\n",
      "Order items loaded successfully: 35\n",
      "All data loaded successfully into MySQL!\n",
      "Data quality report generated\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from dateutil import parser\n",
    "from datetime import datetime\n",
    "import mysql.connector\n",
    "\n",
    "print(\"ETL Pipeline started...\")\n",
    "\n",
    "# ============================================\n",
    "# DATA QUALITY METRICS\n",
    "# ============================================\n",
    "report = []\n",
    "report.append(f\"ETL STARTED AT: {datetime.now()}\")\n",
    "\n",
    "# ============================================\n",
    "# 1. EXTRACT DATA\n",
    "# ============================================\n",
    "customers = pd.read_csv(\"customers_raw.csv\", sep=\";\")\n",
    "products = pd.read_csv(\"products_raw.csv\", sep=\";\")\n",
    "sales = pd.read_csv(\"sales_raw.csv\", sep=\";\")\n",
    "\n",
    "print(\"Data extraction completed\")\n",
    "#print(customers.shape, products.shape, sales.shape)\n",
    "\n",
    "report.append(f\"Customers records read: {len(customers)}\")\n",
    "report.append(f\"Products records read: {len(products)}\")\n",
    "report.append(f\"Sales records read: {len(sales)}\")\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# HELPER FUNCTION\n",
    "# ============================================\n",
    "\n",
    "# Standardize phone\n",
    "\n",
    "def standardize_phone(phone):\n",
    "    if pd.isna(phone) or phone.strip() == \"\":\n",
    "        return \"+91-0000000000\"\n",
    "    phone = re.sub(r'\\D', '', str(phone))  # remove non-digit chars\n",
    "    if phone.startswith('0'):\n",
    "        phone = phone[1:]\n",
    "    if len(phone) > 10:\n",
    "        phone = phone[-10:]  # keep last 10 digits\n",
    "    if len(phone) < 10:\n",
    "        return \"+91-0000000000\"\n",
    "    return f\"+91-{phone}\"\n",
    "\n",
    "\n",
    "# Standardize phone\n",
    "#Convert date to YYYY-MM-DD format\n",
    "\n",
    "def normalize_date(date_val):\n",
    "    if pd.isna(date_val):\n",
    "        return None\n",
    "\n",
    "    for fmt in (\"%d-%m-%Y\", \"%Y-%m-%d\", \"%d/%m/%Y\", \"%m/%d/%Y\",\"%m-%d-%Y\"):\n",
    "        try:\n",
    "            return datetime.strptime(str(date_val), fmt).strftime(\"%Y-%m-%d\")\n",
    "        except ValueError:\n",
    "            continue\n",
    "\n",
    "    return None\n",
    "customers[\"registration_date\"] = customers[\"registration_date\"].apply(normalize_date)\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# 2. DATA CLEANING & TRANSFORMATION\n",
    "# ============================================\n",
    "\n",
    "# Customers Transformation\n",
    "\n",
    "print(\"Started Data Cleaning and Transformation for customer data\")\n",
    "cust_dupes = customers.duplicated().sum()\n",
    "# Remove duplicates\n",
    "\n",
    "customers.drop_duplicates(subset=\"customer_id\", inplace=True)\n",
    "\n",
    "report.append(f\"Customer duplicates removed: {cust_dupes}\")\n",
    "\n",
    "# Fill missing emails reliably\n",
    "customers[\"email\"] = customers[\"email\"].fillna(\n",
    "    \"unknown_\" + customers.index.to_series().astype(str) + \"@mail.com\"\n",
    ")\n",
    "\n",
    "\n",
    "# Standardize phone\n",
    "   \n",
    "customers[\"phone\"] = customers[\"phone\"].apply(standardize_phone)\n",
    "\n",
    "\n",
    "# Normalize registration dates\n",
    "customers[\"registration_date\"] = pd.to_datetime(\n",
    "    customers[\"registration_date\"], errors='coerce'\n",
    ")\n",
    "\n",
    "\n",
    "#Save Cleaned Data \n",
    "customers.to_csv(\"customers_cleaned.csv\", index=False)\n",
    "\n",
    "print(\"Data Cleaning and Tranformation completed, Loaded the clean data to customers_cleaned.csv\")\n",
    "\n",
    "\n",
    "#-------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "#-------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Products Transformation\n",
    "\n",
    "print(\"Started Data Cleaning and Transformation for products data\")\n",
    "prod_dupes = products.duplicated().sum()\n",
    "\n",
    "# Clean column names\n",
    "products.columns = products.columns.str.strip().str.lower()\n",
    "\n",
    "# Remove duplicate rows and duplicate product IDs\n",
    "products.drop_duplicates(inplace=True)\n",
    "products.drop_duplicates(subset=\"product_id\", inplace=True)\n",
    "\n",
    "report.append(f\"Product duplicates removed: {prod_dupes}\")\n",
    "\n",
    "# Handle missing values\n",
    "products[\"price\"] = products[\"price\"].fillna(0.0)\n",
    "products[\"stock_quantity\"] = products[\"stock_quantity\"].fillna(0)\n",
    "products[\"category\"] = products[\"category\"].fillna(\"Unknown\")\n",
    "\n",
    "# Standardize category names (title case)\n",
    "products[\"category\"] = products[\"category\"].str.strip().str.lower().str.title()\n",
    "\n",
    "\n",
    "#Save Cleaned Data \n",
    "products.to_csv(\"products_cleaned.csv\", index=False)\n",
    "\n",
    "print(\"Data Cleaning and Transformation completed, Loaded the clean data to products_cleaned.csv\")\n",
    "\n",
    "#-------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "#-------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "print(\"Started Data Cleaning and Transformation for sales data\")\n",
    "sales_dupes = sales.duplicated().sum()\n",
    "\n",
    "# Sales Transformation\n",
    "\n",
    "sales.columns = sales.columns.str.strip().str.lower()\n",
    "\n",
    "# -----------------------------\n",
    "# Remove Duplicate Transactions\n",
    "# -----------------------------\n",
    "sales.drop_duplicates(inplace=True)\n",
    "\n",
    "# -----------------------------\n",
    "# Handle Missing Values\n",
    "# -----------------------------\n",
    "# Drop rows with missing customer_id or product_id\n",
    "sales = sales.dropna(subset=[\"customer_id\", \"product_id\",\"transaction_date\"])\n",
    "\n",
    "# Fill missing quantity with 1\n",
    "sales[\"quantity\"] = sales[\"quantity\"].fillna(1).astype(int)\n",
    "\n",
    "# Fill missing unit_price with 0.0\n",
    "sales[\"unit_price\"] = sales[\"unit_price\"].fillna(0.0)\n",
    "\n",
    "# Normalize dates\n",
    "sales[\"transaction_date\"] = sales[\"transaction_date\"].apply(normalize_date)\n",
    "\n",
    "# Calculate subtotal\n",
    "sales[\"subtotal\"] = sales[\"quantity\"] * sales[\"unit_price\"]\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Add Surrogate Keys\n",
    "# -----------------------------\n",
    "# Orders table: aggregate total_amount by customer + transaction_date\n",
    "orders = sales.groupby([\"customer_id\", \"transaction_date\"]).agg(\n",
    "    total_amount=pd.NamedAgg(column=\"subtotal\", aggfunc=\"sum\")\n",
    ").reset_index()\n",
    "\n",
    "orders[\"status\"] = \"Pending\"  # Default status\n",
    "\n",
    "\n",
    "# Build final order_items table\n",
    "order_items = sales[[\"customer_id\",\"product_id\",\"quantity\", \"unit_price\", \"subtotal\"]]\n",
    "\n",
    "orders.to_csv(\"orders_cleaned.csv\", index=False)\n",
    "\n",
    "order_items.to_csv(\"order_items_cleaned.csv\", index=False)\n",
    "\n",
    "print(\"Data Cleaning and Transformation completed, Loaded the clean data to orders_cleaned.csv and order_items_cleaned.csv\")\n",
    "print(\"Data cleaning and transformation completed\")\n",
    "print(\"-----------------------------------------------------------------------------------------------\")\n",
    "print(\"-----------------------------------------------------------------------------------------------\")\n",
    "\n",
    "\n",
    "#-------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "#-------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# -----------------------------\n",
    "# Database Connection\n",
    "# -----------------------------\n",
    "try:\n",
    "    conn = mysql.connector.connect(\n",
    "        host=\"localhost\",\n",
    "        user=\"root\",\n",
    "        password=\"harsha123\",  # Replace with your MySQL password\n",
    "        database=\"fleximart\"\n",
    "    )\n",
    "    cursor = conn.cursor()\n",
    "    print(\"Connected to MySQL database 'fleximart'\")\n",
    "except mysql.connector.Error as err:\n",
    "    print(f\"Error: {err}\")\n",
    "    exit()\n",
    "\n",
    "# Disable foreign key checks\n",
    "cursor.execute(\"SET FOREIGN_KEY_CHECKS = 0\")\n",
    "\n",
    "# Truncate tables in correct order\n",
    "cursor.execute(\"TRUNCATE `fleximart`.`order_items`\")\n",
    "cursor.execute(\"TRUNCATE `fleximart`.`orders`\")\n",
    "cursor.execute(\"TRUNCATE `fleximart`.`customers`\")\n",
    "cursor.execute(\"TRUNCATE `fleximart`.`products`\")\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Load Customers\n",
    "# -----------------------------\n",
    "\n",
    "customer_count=0\n",
    "\n",
    "customer_id_map = {}\n",
    "\n",
    "for _, row in customers.iterrows():\n",
    "    cursor.execute(\"\"\"\n",
    "        INSERT INTO customers (first_name, last_name, email, phone, city, registration_date)\n",
    "        VALUES (%s, %s, %s, %s, %s, %s)\n",
    "    \"\"\", (\n",
    "        row[\"first_name\"],\n",
    "        row[\"last_name\"],\n",
    "        row[\"email\"],\n",
    "        row[\"phone\"],\n",
    "        row[\"city\"],\n",
    "        row[\"registration_date\"]\n",
    "    ))\n",
    "    customer_count +=1\n",
    "    \n",
    "    # Capture the MySQL auto-increment ID\n",
    "    mysql_id = cursor.lastrowid\n",
    "    customer_id_map[row[\"customer_id\"]] = mysql_id  # Map CSV ID to MySQL ID\n",
    "\n",
    "conn.commit()\n",
    "\n",
    "print(f\"Customers loaded successfully: {customer_count}\")\n",
    "report.append(f\"Customers loaded successfully: {customer_count}\")\n",
    "\n",
    "# -----------------------------\n",
    "# Load Products\n",
    "# -----------------------------\n",
    "product_count=0\n",
    "\n",
    "products = pd.read_csv(\"products_cleaned.csv\")\n",
    "product_id_map = {}  # CSV product_id â†’ MySQL product_id\n",
    "\n",
    "for _, row in products.iterrows():\n",
    "    cursor.execute(\"\"\"\n",
    "        INSERT INTO products (product_name, category, price, stock_quantity)\n",
    "        VALUES (%s, %s, %s, %s)\n",
    "    \"\"\", (\n",
    "        row[\"product_name\"],\n",
    "        row[\"category\"],\n",
    "        row[\"price\"],\n",
    "        row[\"stock_quantity\"]\n",
    "    ))\n",
    "    product_count +=1\n",
    "\n",
    "    mysql_product_id = cursor.lastrowid\n",
    "    product_id_map[row[\"product_id\"]] = mysql_product_id\n",
    "conn.commit()\n",
    "\n",
    "print(f\"Products loaded successfully: {product_count}\")\n",
    "report.append(f\"Products loaded successfully: {product_count}\")\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Load Orders\n",
    "# -----------------------------\n",
    "\n",
    "order_count=0\n",
    "\n",
    "# Insert orders and capture MySQL order_ids\n",
    "\n",
    "order_id_map = {}\n",
    "for _, row in orders.iterrows():\n",
    "    cursor.execute(\"\"\"\n",
    "        INSERT INTO orders (customer_id, order_date, total_amount, status)\n",
    "        VALUES (%s, %s, %s, %s)\n",
    "    \"\"\", (\n",
    "        customer_id_map[row[\"customer_id\"]],  # use mapped MySQL ID\n",
    "        row[\"transaction_date\"],\n",
    "        row[\"total_amount\"],\n",
    "        row[\"status\"]\n",
    "    ))\n",
    "    order_count += 1\n",
    "    order_id_map[(row[\"customer_id\"], row[\"transaction_date\"])] = cursor.lastrowid\n",
    "\n",
    "conn.commit()\n",
    "print(f\"Orders loaded successfully: {order_count}\")\n",
    "report.append(f\"Orders loaded successfully: {order_count}\")\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Load Order Items\n",
    "# -----------------------------\n",
    "item_count = 0\n",
    "sales[\"order_id\"] = sales.apply(\n",
    "    lambda x: order_id_map.get((x[\"customer_id\"], x[\"transaction_date\"])),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "for _, row in sales.iterrows():\n",
    "    cursor.execute(\"\"\"\n",
    "        INSERT INTO order_items (order_id, product_id, quantity, unit_price, subtotal)\n",
    "        VALUES (%s, %s, %s, %s, %s)\n",
    "    \"\"\", (\n",
    "        row[\"order_id\"],\n",
    "        product_id_map[row[\"product_id\"]],  # assuming product_id CSV matches MySQL products table\n",
    "        row[\"quantity\"],\n",
    "        row[\"unit_price\"],\n",
    "        row[\"quantity\"] * row[\"unit_price\"]\n",
    "    ))\n",
    "    item_count += 1\n",
    "\n",
    "conn.commit()\n",
    "print(f\"Order items loaded successfully: {item_count}\")\n",
    "report.append(f\"Order items loaded successfully: {item_count}\")\n",
    "# Enable foreign key checks\n",
    "cursor.execute(\"SET FOREIGN_KEY_CHECKS = 1\")\n",
    "\n",
    "# -----------------------------\n",
    "# Commit & Close\n",
    "# -----------------------------\n",
    "conn.commit()\n",
    "cursor.close()\n",
    "conn.close()\n",
    "print(\"All data loaded successfully into MySQL!\")\n",
    "\n",
    "\n",
    "#-------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "#-------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# ============================================\n",
    "#DATA QUALITY REPORT\n",
    "# ============================================\n",
    "\n",
    "report.append(f\"ETL COMPLETED AT: {datetime.now()}\")\n",
    "\n",
    "with open(\"data_quality_report.txt\", \"w\") as f:\n",
    "    for line in report:\n",
    "        f.write(line + \"\\n\")\n",
    "\n",
    "print(\"Data quality report generated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c923ea-dfb4-468e-80e1-1733194f2dad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
